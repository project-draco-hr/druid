{
  final ServiceEmitter emitter=EasyMock.createMock(ServiceEmitter.class);
  EmittingLogger.registerEmitter(emitter);
  tmp=Files.createTempDir();
  final TaskQueueConfig tqc=new DefaultObjectMapper().readValue("{\"startDelay\":\"PT0S\", \"restartDelay\":\"PT1S\"}",TaskQueueConfig.class);
  ts=new HeapMemoryTaskStorage(new TaskStorageConfig(){
  }
);
  tsqa=new TaskStorageQueryAdapter(ts);
  tl=new TaskLockbox(ts);
  mdc=newMockMDC();
  tac=new LocalTaskActionClientFactory(ts,new TaskActionToolbox(tl,mdc,newMockEmitter()));
  tb=new TaskToolboxFactory(new TaskConfig(tmp.toString(),null,null,50000),tac,newMockEmitter(),new DataSegmentPusher(){
    @Override public String getPathForHadoop(    String dataSource){
      throw new UnsupportedOperationException();
    }
    @Override public DataSegment push(    File file,    DataSegment segment) throws IOException {
      return segment;
    }
  }
,new DataSegmentKiller(){
    @Override public void kill(    DataSegment segments) throws SegmentLoadingException {
    }
  }
,new DataSegmentMover(){
    @Override public DataSegment move(    DataSegment dataSegment,    Map<String,Object> targetLoadSpec) throws SegmentLoadingException {
      return dataSegment;
    }
  }
,new DataSegmentArchiver(){
    @Override public DataSegment archive(    DataSegment segment) throws SegmentLoadingException {
      return segment;
    }
    @Override public DataSegment restore(    DataSegment segment) throws SegmentLoadingException {
      return segment;
    }
  }
,null,null,null,null,null,new SegmentLoaderFactory(new OmniSegmentLoader(ImmutableMap.<String,DataSegmentPuller>of("local",new LocalDataSegmentPuller()),null,new SegmentLoaderConfig(){
    @Override public List<StorageLocationConfig> getLocations(){
      return Lists.newArrayList();
    }
  }
)),new DefaultObjectMapper(),new OffheapBufferPool(1024 * 1024));
  tr=new ThreadPoolTaskRunner(tb);
  tq=new TaskQueue(tqc,ts,tr,tac,tl,emitter);
  tq.start();
}
