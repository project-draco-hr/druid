{
  spec=readAndVerifyDatasourceIngestionSpec(context.getConfiguration(),HadoopDruidIndexerConfig.JSON_MAPPER);
  List<WindowedDataSegment> segments=((DatasourceInputSplit)split).getSegments();
  List<WindowedStorageAdapter> adapters=Lists.transform(segments,new Function<WindowedDataSegment,WindowedStorageAdapter>(){
    @Override public WindowedStorageAdapter apply(    WindowedDataSegment segment){
      try {
        logger.info("Getting storage path for segment [%s]",segment.getSegment().getIdentifier());
        Path path=new Path(JobHelper.getURIFromSegment(segment.getSegment()));
        logger.info("Fetch segment files from [%s]",path);
        File dir=Files.createTempDir();
        tmpSegmentDirs.add(dir);
        logger.info("Locally storing fetched segment at [%s]",dir);
        JobHelper.unzipNoGuava(path,context.getConfiguration(),dir,context);
        logger.info("finished fetching segment files");
        QueryableIndex index=HadoopDruidIndexerConfig.INDEX_IO.loadIndex(dir);
        indexes.add(index);
        numRows+=index.getNumRows();
        return new WindowedStorageAdapter(new QueryableIndexStorageAdapter(index),segment.getInterval());
      }
 catch (      IOException ex) {
        throw Throwables.propagate(ex);
      }
    }
  }
);
  firehose=new IngestSegmentFirehose(adapters,spec.getDimensions(),spec.getMetrics(),spec.getFilter(),spec.getGranularity());
}
