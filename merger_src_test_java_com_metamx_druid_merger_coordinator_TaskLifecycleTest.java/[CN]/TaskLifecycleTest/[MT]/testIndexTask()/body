{
  final Task indexTask=new IndexTask(null,"foo",new UniformGranularitySpec(Granularity.DAY,ImmutableList.of(new Interval("2010-01-01/P2D"))),new AggregatorFactory[]{new DoubleSumAggregatorFactory("met","met")},QueryGranularity.NONE,10000,newMockFirehoseFactory(ImmutableList.of(IR("2010-01-01T01","x","y",1),IR("2010-01-01T01","x","z",1),IR("2010-01-02T01","a","b",2),IR("2010-01-02T01","a","c",1))),-1);
  final TaskStatus mergedStatus=runTask(indexTask);
  final TaskStatus status=ts.getStatus(indexTask.getId()).get();
  final List<DataSegment> publishedSegments=byIntervalOrdering.sortedCopy(mdc.getPublished());
  final List<DataSegment> loggedSegments=byIntervalOrdering.sortedCopy(tsqa.getSameGroupNewSegments(indexTask.getId()));
  Assert.assertEquals("statusCode",TaskStatus.Status.SUCCESS,status.getStatusCode());
  Assert.assertEquals("merged statusCode",TaskStatus.Status.SUCCESS,mergedStatus.getStatusCode());
  Assert.assertEquals("segments logged vs published",loggedSegments,publishedSegments);
  Assert.assertEquals("num segments published",2,mdc.getPublished().size());
  Assert.assertEquals("num segments nuked",0,mdc.getNuked().size());
  Assert.assertEquals("segment1 datasource","foo",publishedSegments.get(0).getDataSource());
  Assert.assertEquals("segment1 interval",new Interval("2010-01-01/P1D"),publishedSegments.get(0).getInterval());
  Assert.assertEquals("segment1 dimensions",ImmutableList.of("dim1","dim2"),publishedSegments.get(0).getDimensions());
  Assert.assertEquals("segment1 metrics",ImmutableList.of("met"),publishedSegments.get(0).getMetrics());
  Assert.assertEquals("segment2 datasource","foo",publishedSegments.get(1).getDataSource());
  Assert.assertEquals("segment2 interval",new Interval("2010-01-02/P1D"),publishedSegments.get(1).getInterval());
  Assert.assertEquals("segment2 dimensions",ImmutableList.of("dim1","dim2"),publishedSegments.get(1).getDimensions());
  Assert.assertEquals("segment2 metrics",ImmutableList.of("met"),publishedSegments.get(1).getMetrics());
}
