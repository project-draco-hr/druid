{
  final int dimensionCount=5;
  final ArrayList<AggregatorFactory> ingestAggregatorFactories=new ArrayList<>(dimensionCount + 1);
  ingestAggregatorFactories.add(new CountAggregatorFactory("rows"));
  for (int i=0; i < dimensionCount; ++i) {
    ingestAggregatorFactories.add(new LongSumAggregatorFactory(String.format("sumResult%s",i),String.format("Dim_%s",i)));
    ingestAggregatorFactories.add(new DoubleSumAggregatorFactory(String.format("doubleSumResult%s",i),String.format("Dim_%s",i)));
  }
  final ArrayList<AggregatorFactory> queryAggregatorFactories=new ArrayList<>(dimensionCount + 1);
  queryAggregatorFactories.add(new CountAggregatorFactory("rows"));
  for (int i=0; i < dimensionCount; ++i) {
    queryAggregatorFactories.add(new LongSumAggregatorFactory(String.format("sumResult%s",i),String.format("sumResult%s",i)));
    queryAggregatorFactories.add(new DoubleSumAggregatorFactory(String.format("doubleSumResult%s",i),String.format("doubleSumResult%s",i)));
  }
  final IncrementalIndex index=indexCreator.createIndex(ingestAggregatorFactories.toArray(new AggregatorFactory[dimensionCount]));
  final int taskCount=30;
  final int concurrentThreads=3;
  final int elementsPerThread=100;
  final ListeningExecutorService indexExecutor=MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(concurrentThreads,new ThreadFactoryBuilder().setDaemon(false).setNameFormat("index-executor-%d").setPriority(Thread.MIN_PRIORITY).build()));
  final ListeningExecutorService queryExecutor=MoreExecutors.listeningDecorator(Executors.newFixedThreadPool(concurrentThreads,new ThreadFactoryBuilder().setDaemon(false).setNameFormat("query-executor-%d").build()));
  final long timestamp=System.currentTimeMillis();
  final Interval queryInterval=new Interval("1900-01-01T00:00:00Z/2900-01-01T00:00:00Z");
  final List<ListenableFuture<?>> indexFutures=new LinkedList<>();
  final List<ListenableFuture<?>> queryFutures=new LinkedList<>();
  final Segment incrementalIndexSegment=new IncrementalIndexSegment(index,null);
  final QueryRunnerFactory factory=new TimeseriesQueryRunnerFactory(new TimeseriesQueryQueryToolChest(new QueryConfig()),new TimeseriesQueryEngine(),QueryRunnerTestHelper.NOOP_QUERYWATCHER);
  final AtomicInteger currentlyRunning=new AtomicInteger(0);
  final AtomicBoolean concurrentlyRan=new AtomicBoolean(false);
  final AtomicBoolean someoneRan=new AtomicBoolean(false);
  for (int j=0; j < taskCount; j++) {
    indexFutures.add(indexExecutor.submit(new Runnable(){
      @Override public void run(){
        currentlyRunning.incrementAndGet();
        try {
          for (int i=0; i < elementsPerThread; i++) {
            index.add(getLongRow(timestamp + i,i,dimensionCount));
          }
        }
 catch (        IndexSizeExceededException e) {
          throw Throwables.propagate(e);
        }
        currentlyRunning.decrementAndGet();
        someoneRan.set(true);
      }
    }
));
    queryFutures.add(queryExecutor.submit(new Runnable(){
      @Override public void run(){
        QueryRunner<Result<TimeseriesResultValue>> runner=new FinalizeResultsQueryRunner<Result<TimeseriesResultValue>>(factory.createRunner(incrementalIndexSegment),factory.getToolchest());
        TimeseriesQuery query=Druids.newTimeseriesQueryBuilder().dataSource("xxx").granularity(QueryGranularity.ALL).intervals(ImmutableList.of(queryInterval)).aggregators(queryAggregatorFactories).build();
        Map<String,Object> context=new HashMap<String,Object>();
        for (        Result<TimeseriesResultValue> result : Sequences.toList(runner.run(query,context),new LinkedList<Result<TimeseriesResultValue>>())) {
          if (someoneRan.get()) {
            Assert.assertTrue(result.getValue().getDoubleMetric("doubleSumResult0") > 0);
          }
        }
        if (currentlyRunning.get() > 0) {
          concurrentlyRan.set(true);
        }
      }
    }
));
  }
  List<ListenableFuture<?>> allFutures=new ArrayList<>(queryFutures.size() + indexFutures.size());
  allFutures.addAll(queryFutures);
  allFutures.addAll(indexFutures);
  Futures.allAsList(allFutures).get();
  Assert.assertTrue("Did not hit concurrency, please try again",concurrentlyRan.get());
  queryExecutor.shutdown();
  indexExecutor.shutdown();
  QueryRunner<Result<TimeseriesResultValue>> runner=new FinalizeResultsQueryRunner<Result<TimeseriesResultValue>>(factory.createRunner(incrementalIndexSegment),factory.getToolchest());
  TimeseriesQuery query=Druids.newTimeseriesQueryBuilder().dataSource("xxx").granularity(QueryGranularity.ALL).intervals(ImmutableList.of(queryInterval)).aggregators(queryAggregatorFactories).build();
  Map<String,Object> context=new HashMap<String,Object>();
  List<Result<TimeseriesResultValue>> results=Sequences.toList(runner.run(query,context),new LinkedList<Result<TimeseriesResultValue>>());
  for (  Result<TimeseriesResultValue> result : results) {
    Assert.assertEquals(elementsPerThread,result.getValue().getLongMetric("rows").intValue());
    for (int i=0; i < dimensionCount; ++i) {
      Assert.assertEquals(String.format("Failed long sum on dimension %d",i),elementsPerThread * taskCount,result.getValue().getLongMetric(String.format("sumResult%s",i)).intValue());
      Assert.assertEquals(String.format("Failed double sum on dimension %d",i),elementsPerThread * taskCount,result.getValue().getDoubleMetric(String.format("doubleSumResult%s",i)).intValue());
    }
  }
}
