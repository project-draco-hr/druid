{
  final GranularitySpec granularitySpec=ingestionSchema.getDataSchema().getGranularitySpec();
  final int targetPartitionSize=ingestionSchema.getTuningConfig().getTargetPartitionSize();
  final TaskLock myLock=Iterables.getOnlyElement(getTaskLocks(toolbox));
  final Set<DataSegment> segments=Sets.newHashSet();
  final Set<Interval> validIntervals=Sets.intersection(granularitySpec.bucketIntervals().get(),getDataIntervals());
  if (validIntervals.isEmpty()) {
    throw new ISE("No valid data intervals found. Check your configs!");
  }
  for (  final Interval bucket : validIntervals) {
    final List<ShardSpec> shardSpecs;
    if (targetPartitionSize > 0) {
      shardSpecs=determinePartitions(bucket,targetPartitionSize,granularitySpec.getQueryGranularity());
    }
 else {
      int numShards=ingestionSchema.getTuningConfig().getNumShards();
      if (numShards > 0) {
        shardSpecs=Lists.newArrayList();
        for (int i=0; i < numShards; i++) {
          shardSpecs.add(new HashBasedNumberedShardSpec(i,numShards,null,jsonMapper));
        }
      }
 else {
        shardSpecs=ImmutableList.<ShardSpec>of(NoneShardSpec.instance());
      }
    }
    for (    final ShardSpec shardSpec : shardSpecs) {
      final DataSegment segment=generateSegment(toolbox,ingestionSchema.getDataSchema(),shardSpec,bucket,myLock.getVersion());
      segments.add(segment);
    }
  }
  toolbox.publishSegments(segments);
  return TaskStatus.success(getId());
}
