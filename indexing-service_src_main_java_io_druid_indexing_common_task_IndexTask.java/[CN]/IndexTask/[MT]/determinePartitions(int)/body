{
  Map<Interval,List<ShardSpec>> retVal=Maps.newLinkedHashMap();
  log.info("Determining partitions with targetPartitionSize[%d]",targetPartitionSize);
  final Set<String> unusableDimensions=Sets.newHashSet();
  try (Firehose firehose=firehoseFactory.connect()){
    if (!firehose.hasMore()) {
      log.error("Unable to find any events to ingest! Check your firehose config!");
      return retVal;
    }
    InputRow inputRow=firehose.nextRow();
    for (    Interval interval : granularitySpec.bucketIntervals()) {
      final Map<String,TreeMultiset<String>> dimensionValueMultisets=Maps.newHashMap();
      boolean hasEventsInInterval=false;
      boolean done=false;
      while (!done && interval.contains(inputRow.getTimestampFromEpoch())) {
        hasEventsInInterval=true;
        for (        final String dim : inputRow.getDimensions()) {
          final List<String> dimValues=inputRow.getDimension(dim);
          if (!unusableDimensions.contains(dim)) {
            if (dimValues.size() == 1) {
              TreeMultiset<String> dimensionValueMultiset=dimensionValueMultisets.get(dim);
              if (dimensionValueMultiset == null) {
                dimensionValueMultiset=TreeMultiset.create();
                dimensionValueMultisets.put(dim,dimensionValueMultiset);
              }
              dimensionValueMultiset.add(dimValues.get(0));
            }
 else {
              unusableDimensions.add(dim);
              dimensionValueMultisets.remove(dim);
            }
          }
        }
        if (firehose.hasMore()) {
          inputRow=firehose.nextRow();
        }
 else {
          done=true;
        }
      }
      if (hasEventsInInterval) {
        if (targetPartitionSize == 0) {
          retVal.put(interval,ImmutableList.<ShardSpec>of(new NoneShardSpec()));
        }
 else {
          retVal.put(interval,determineShardSpecs(dimensionValueMultisets));
        }
      }
    }
  }
   return retVal;
}
