{
  final String storageDir=DataSegmentPusherUtil.getHdfsStorageDir(segment);
  log.info("Copying segment[%s] to HDFS at location[%s/%s]",segment.getIdentifier(),config.getStorageDirectory(),storageDir);
  Path tmpFile=new Path(String.format("%s/%s/index.zip",config.getStorageDirectory(),UUIDUtils.generateUuid()));
  FileSystem fs=tmpFile.getFileSystem(hadoopConfig);
  fs.mkdirs(tmpFile.getParent());
  log.info("Compressing files from[%s] to [%s]",inDir,tmpFile);
  final long size;
  final DataSegment dataSegment;
  try (FSDataOutputStream out=fs.create(tmpFile)){
    size=CompressionUtils.zip(inDir,out);
    dataSegment=createDescriptorFile(segment.withLoadSpec(makeLoadSpec(tmpFile)).withSize(size).withBinaryVersion(SegmentUtils.getVersionFromDir(inDir)),tmpFile.getParent(),fs);
    Path outDir=new Path(String.format("%s/%s",config.getStorageDirectory(),storageDir));
    if (!fs.rename(tmpFile.getParent(),outDir)) {
      if (!fs.delete(tmpFile.getParent(),true)) {
        log.error("Failed to delete temp directory[%s]",tmpFile);
      }
      if (fs.exists(outDir)) {
        log.info("Unable to rename temp directory[%s] to segment directory[%s]. It is already pushed by a replica task.",tmpFile,outDir);
      }
 else {
        throw new IOException(String.format("Failed to rename temp directory[%s] and segment directory[%s] is not present.",tmpFile,outDir));
      }
    }
  }
   return dataSegment;
}
