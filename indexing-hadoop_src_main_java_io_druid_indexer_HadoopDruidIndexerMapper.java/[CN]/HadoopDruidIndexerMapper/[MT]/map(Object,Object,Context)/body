{
  try {
    final InputRow inputRow;
    try {
      inputRow=parseInputRow(value,parser);
    }
 catch (    Exception e) {
      if (config.isIgnoreInvalidRows()) {
        log.debug(e,"Ignoring invalid row [%s] due to parsing error",value.toString());
        context.getCounter(HadoopDruidIndexerConfig.IndexJobCounters.INVALID_ROW_COUNTER).increment(1);
        return;
      }
 else {
        throw e;
      }
    }
    if (!granularitySpec.bucketIntervals().isPresent() || granularitySpec.bucketInterval(new DateTime(inputRow.getTimestampFromEpoch())).isPresent()) {
      innerMap(inputRow,value,context);
    }
  }
 catch (  RuntimeException e) {
    throw new RE(e,"Failure on row[%s]",value);
  }
}
