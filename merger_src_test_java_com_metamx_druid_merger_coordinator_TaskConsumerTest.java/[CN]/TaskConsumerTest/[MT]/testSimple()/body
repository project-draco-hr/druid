{
  final TaskStorage ts=new LocalTaskStorage();
  final TaskQueue tq=new TaskQueue(ts);
  final TaskRunner tr=new LocalTaskRunner(new TaskToolbox(null,null,null,null,null,null),Executors.newSingleThreadExecutor());
  final MockMergerDBCoordinator mdc=newMockMDC();
  final TaskConsumer tc=new TaskConsumer(tq,tr,mdc,newMockEmitter());
  tq.start();
  tc.start();
  try {
    tq.add(new AbstractTask("id1","id1","ds",new Interval("2012-01-01/P1D")){
      @Override public Type getType(){
        return Type.TEST;
      }
      @Override public TaskStatus run(      TaskContext context,      TaskToolbox toolbox,      TaskCallback callback) throws Exception {
        return TaskStatus.success(getId()).withSegments(ImmutableSet.of(DataSegment.builder().dataSource("ds").interval(new Interval("2012-01-01/P1D")).version(context.getVersion()).build()));
      }
    }
);
    while (ts.getStatus("id1").get().isRunnable()) {
      Thread.sleep(100);
    }
    final TaskStatus status=ts.getStatus("id1").get();
    Assert.assertTrue("nextTasks",status.getNextTasks().isEmpty());
    Assert.assertEquals("segments.size",1,status.getSegments().size());
    Assert.assertEquals("segmentsNuked.size",0,status.getSegmentsNuked().size());
    Assert.assertEquals("segments published",status.getSegments(),mdc.getPublished());
    Assert.assertEquals("segments nuked",status.getSegmentsNuked(),mdc.getNuked());
  }
 catch (  Exception e) {
    throw Throwables.propagate(e);
  }
 finally {
    tc.stop();
    tq.stop();
  }
}
