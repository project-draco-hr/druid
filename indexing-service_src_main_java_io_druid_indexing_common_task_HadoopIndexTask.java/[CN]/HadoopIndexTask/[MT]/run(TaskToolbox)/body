{
  final DefaultTeslaAether aetherClient=Initialization.getAetherClient(extensionsConfig);
  final ClassLoader hadoopLoader=Initialization.getClassLoaderForCoordinates(aetherClient,hadoopCoordinates);
  final List<URL> allURLs=Lists.newArrayList();
  final List<URL> nonHadoopURLs=Lists.newArrayList();
  for (  String coordinate : extensionsConfig.getCoordinates()) {
    final ClassLoader coordinateLoader=Initialization.getClassLoaderForCoordinates(aetherClient,coordinate);
    nonHadoopURLs.addAll(Arrays.asList(((URLClassLoader)coordinateLoader).getURLs()));
  }
  nonHadoopURLs.addAll(Arrays.asList(((URLClassLoader)HadoopIndexTask.class.getClassLoader()).getURLs()));
  allURLs.addAll(nonHadoopURLs);
  allURLs.addAll(Arrays.asList(((URLClassLoader)hadoopLoader).getURLs()));
  final URLClassLoader loader=new URLClassLoader(allURLs.toArray(new URL[allURLs.size()]),null);
  Thread.currentThread().setContextClassLoader(loader);
  System.setProperty("druid.hadoop.internal.classpath",Joiner.on(File.pathSeparator).join(nonHadoopURLs));
  final Class<?> mainClass=loader.loadClass(HadoopIndexTaskInnerProcessing.class.getName());
  final Method mainMethod=mainClass.getMethod("runTask",String[].class);
  final TaskLock myLock=Iterables.getOnlyElement(getTaskLocks(toolbox));
  log.info("Setting version to: %s",myLock.getVersion());
  String[] args=new String[]{toolbox.getObjectMapper().writeValueAsString(schema),myLock.getVersion(),toolbox.getConfig().getHadoopWorkingPath(),toolbox.getSegmentPusher().getPathForHadoop(getDataSource())};
  String segments=(String)mainMethod.invoke(null,new Object[]{args});
  if (segments != null) {
    List<DataSegment> publishedSegments=toolbox.getObjectMapper().readValue(segments,new TypeReference<List<DataSegment>>(){
    }
);
    toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.copyOf(publishedSegments)));
    return TaskStatus.success(getId());
  }
 else {
    return TaskStatus.failure(getId());
  }
}
