{
  final DefaultTeslaAether aetherClient=new DefaultTeslaAether();
  final ClassLoader hadoopLoader=Initialization.getClassLoaderForCoordinates(aetherClient,hadoopCoordinates);
  final URL[] urLs=((URLClassLoader)hadoopLoader).getURLs();
  final URL[] nonHadoopUrls=((URLClassLoader)HadoopIndexTask.class.getClassLoader()).getURLs();
  List<URL> theURLS=Lists.newArrayList();
  theURLS.addAll(Arrays.asList(urLs));
  theURLS.addAll(Arrays.asList(nonHadoopUrls));
  final URLClassLoader loader=new URLClassLoader(theURLS.toArray(new URL[theURLS.size()]),null);
  Thread.currentThread().setContextClassLoader(loader);
  System.setProperty("druid.hadoop.internal.classpath",Joiner.on(File.pathSeparator).join(nonHadoopUrls));
  final Class<?> mainClass=loader.loadClass(HadoopIndexTaskInnerProcessing.class.getName());
  final Method mainMethod=mainClass.getMethod("runTask",String[].class);
  final TaskLock myLock=Iterables.getOnlyElement(getTaskLocks(toolbox));
  log.info("Setting version to: %s",myLock.getVersion());
  String[] args=new String[]{toolbox.getObjectMapper().writeValueAsString(schema),myLock.getVersion(),toolbox.getConfig().getHadoopWorkingPath(),toolbox.getSegmentPusher().getPathForHadoop(getDataSource())};
  String segments=(String)mainMethod.invoke(null,new Object[]{args});
  if (segments != null) {
    List<DataSegment> publishedSegments=toolbox.getObjectMapper().readValue(segments,new TypeReference<List<DataSegment>>(){
    }
);
    toolbox.getTaskActionClient().submit(new SegmentInsertAction(ImmutableSet.copyOf(publishedSegments)));
    return TaskStatus.success(getId());
  }
 else {
    return TaskStatus.failure(getId());
  }
}
