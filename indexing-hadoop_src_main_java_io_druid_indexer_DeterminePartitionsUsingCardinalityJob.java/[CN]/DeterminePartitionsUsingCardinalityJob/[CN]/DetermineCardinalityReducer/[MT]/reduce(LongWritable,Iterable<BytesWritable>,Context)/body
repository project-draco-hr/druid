{
  HyperLogLog aggregate=new HyperLogLog(20);
  for (  BytesWritable value : values) {
    HyperLogLog logValue=HyperLogLog.Builder.build(value.getBytes());
    try {
      aggregate.addAll(logValue);
    }
 catch (    CardinalityMergeException e) {
      e.printStackTrace();
    }
  }
  final Path outPath=config.makeSegmentPartitionInfoPath(new Bucket(0,new DateTime(key.get()),0));
  new Exception("creating output path" + outPath).printStackTrace();
  final OutputStream out=Utils.makePathAndOutputStream(context,outPath,config.isOverwriteFiles());
  try {
    HadoopDruidIndexerConfig.jsonMapper.writerWithType(new TypeReference<Long>(){
    }
).writeValue(out,aggregate.cardinality());
  }
  finally {
    Closeables.close(out,false);
  }
}
