{
  try {
    final List<String> allCoordinates=Lists.newArrayList();
    if (coordinates != null) {
      allCoordinates.addAll(coordinates);
    }
    if (!noDefaultHadoop) {
      allCoordinates.addAll(DEFAULT_HADOOP_COORDINATES);
    }
    final List<URL> extensionURLs=Lists.newArrayList();
    for (    final File extension : Initialization.getExtensionFilesToLoad(extensionsConfig)) {
      final ClassLoader extensionLoader=Initialization.getClassLoaderForExtension(extension);
      extensionURLs.addAll(Arrays.asList(((URLClassLoader)extensionLoader).getURLs()));
    }
    final List<URL> nonHadoopURLs=Lists.newArrayList();
    nonHadoopURLs.addAll(Arrays.asList(((URLClassLoader)CliHadoopIndexer.class.getClassLoader()).getURLs()));
    final List<URL> driverURLs=Lists.newArrayList();
    driverURLs.addAll(nonHadoopURLs);
    for (    File hadoopDependency : Initialization.getHadoopDependencyFilesToLoad(allCoordinates,extensionsConfig)) {
      final ClassLoader hadoopLoader=Initialization.getClassLoaderForExtension(hadoopDependency);
      driverURLs.addAll(Arrays.asList(((URLClassLoader)hadoopLoader).getURLs()));
    }
    final URLClassLoader loader=new URLClassLoader(driverURLs.toArray(new URL[driverURLs.size()]),null);
    Thread.currentThread().setContextClassLoader(loader);
    final List<URL> jobUrls=Lists.newArrayList();
    jobUrls.addAll(nonHadoopURLs);
    jobUrls.addAll(extensionURLs);
    System.setProperty("druid.hadoop.internal.classpath",Joiner.on(File.pathSeparator).join(jobUrls));
    final Class<?> mainClass=loader.loadClass(Main.class.getName());
    final Method mainMethod=mainClass.getMethod("main",String[].class);
    String[] args=new String[]{"internal","hadoop-indexer",argumentSpec};
    mainMethod.invoke(null,new Object[]{args});
  }
 catch (  Exception e) {
    log.error(e,"failure!!!!");
    System.exit(1);
  }
}
