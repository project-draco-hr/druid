{
  final Druids.TimeseriesQueryBuilder builder=Druids.newTimeseriesQueryBuilder().dataSource(DATA_SOURCE).intervals(SEG_SPEC).filters(DIM_FILTER).granularity(GRANULARITY).aggregators(AGGS).postAggregators(POST_AGGS).context(CONTEXT);
  QueryRunner runner=new FinalizeResultsQueryRunner(client,new TimeseriesQueryQueryToolChest(QueryRunnerTestHelper.NoopIntervalChunkingQueryRunnerDecorator()));
  testQueryCaching(runner,builder.build(),new Interval("2011-01-01/2011-01-02"),makeTimeResults(new DateTime("2011-01-01"),50,5000),new Interval("2011-01-02/2011-01-03"),makeTimeResults(new DateTime("2011-01-02"),30,6000),new Interval("2011-01-04/2011-01-05"),makeTimeResults(new DateTime("2011-01-04"),23,85312),new Interval("2011-01-05/2011-01-10"),makeTimeResults(new DateTime("2011-01-05"),85,102,new DateTime("2011-01-06"),412,521,new DateTime("2011-01-07"),122,21894,new DateTime("2011-01-08"),5,20,new DateTime("2011-01-09"),18,521),new Interval("2011-01-05/2011-01-10"),makeTimeResults(new DateTime("2011-01-05T01"),80,100,new DateTime("2011-01-06T01"),420,520,new DateTime("2011-01-07T01"),12,2194,new DateTime("2011-01-08T01"),59,201,new DateTime("2011-01-09T01"),181,52));
  HashMap<String,List> context=new HashMap<String,List>();
  TestHelper.assertExpectedResults(makeRenamedTimeResults(new DateTime("2011-01-01"),50,5000,new DateTime("2011-01-02"),30,6000,new DateTime("2011-01-04"),23,85312,new DateTime("2011-01-05"),85,102,new DateTime("2011-01-05T01"),80,100,new DateTime("2011-01-06"),412,521,new DateTime("2011-01-06T01"),420,520,new DateTime("2011-01-07"),122,21894,new DateTime("2011-01-07T01"),12,2194,new DateTime("2011-01-08"),5,20,new DateTime("2011-01-08T01"),59,201,new DateTime("2011-01-09"),18,521,new DateTime("2011-01-09T01"),181,52),runner.run(builder.intervals("2011-01-01/2011-01-10").aggregators(RENAMED_AGGS).postAggregators(RENAMED_POST_AGGS).build(),context));
}
