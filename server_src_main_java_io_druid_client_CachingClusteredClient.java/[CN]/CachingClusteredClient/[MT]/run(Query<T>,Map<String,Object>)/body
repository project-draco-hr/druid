{
  final QueryToolChest<T,Query<T>> toolChest=warehouse.getToolChest(query);
  final CacheStrategy<T,Object,Query<T>> strategy=toolChest.getCacheStrategy(query);
  final Map<DruidServer,List<SegmentDescriptor>> serverSegments=Maps.newTreeMap();
  final List<Pair<Interval,byte[]>> cachedResults=Lists.newArrayList();
  final Map<String,CachePopulator> cachePopulatorMap=Maps.newHashMap();
  final boolean useCache=query.getContextUseCache(true) && strategy != null && cacheConfig.isUseCache() && cacheConfig.isQueryCacheable(query);
  final boolean populateCache=query.getContextPopulateCache(true) && strategy != null && cacheConfig.isPopulateCache() && cacheConfig.isQueryCacheable(query);
  final boolean isBySegment=query.getContextBySegment(false);
  final ImmutableMap.Builder<String,Object> contextBuilder=new ImmutableMap.Builder<>();
  final int priority=query.getContextPriority(0);
  contextBuilder.put("priority",priority);
  if (populateCache) {
    contextBuilder.put(CacheConfig.POPULATE_CACHE,false);
    contextBuilder.put("bySegment",true);
  }
  contextBuilder.put("intermediate",true);
  TimelineLookup<String,ServerSelector> timeline=serverView.getTimeline(query.getDataSource());
  if (timeline == null) {
    return Sequences.empty();
  }
  Set<Pair<ServerSelector,SegmentDescriptor>> segments=Sets.newLinkedHashSet();
  List<TimelineObjectHolder<String,ServerSelector>> serversLookup=Lists.newLinkedList();
  for (  Interval interval : query.getIntervals()) {
    Iterables.addAll(serversLookup,timeline.lookup(interval));
  }
  final List<TimelineObjectHolder<String,ServerSelector>> filteredServersLookup=toolChest.filterSegments(query,serversLookup);
  for (  TimelineObjectHolder<String,ServerSelector> holder : filteredServersLookup) {
    for (    PartitionChunk<ServerSelector> chunk : holder.getObject()) {
      ServerSelector selector=chunk.getObject();
      final SegmentDescriptor descriptor=new SegmentDescriptor(holder.getInterval(),holder.getVersion(),chunk.getChunkNumber());
      segments.add(Pair.of(selector,descriptor));
    }
  }
  final byte[] queryCacheKey;
  if ((populateCache || useCache) && !isBySegment) {
    queryCacheKey=strategy.computeCacheKey(query);
  }
 else {
    queryCacheKey=null;
  }
  if (queryCacheKey != null) {
    Map<Pair<ServerSelector,SegmentDescriptor>,Cache.NamedKey> cacheKeys=Maps.newLinkedHashMap();
    for (    Pair<ServerSelector,SegmentDescriptor> segment : segments) {
      final Cache.NamedKey segmentCacheKey=CacheUtil.computeSegmentCacheKey(segment.lhs.getSegment().getIdentifier(),segment.rhs,queryCacheKey);
      cacheKeys.put(segment,segmentCacheKey);
    }
    final Map<Cache.NamedKey,byte[]> cachedValues;
    if (useCache) {
      cachedValues=cache.getBulk(cacheKeys.values());
    }
 else {
      cachedValues=ImmutableMap.of();
    }
    for (    Map.Entry<Pair<ServerSelector,SegmentDescriptor>,Cache.NamedKey> entry : cacheKeys.entrySet()) {
      Pair<ServerSelector,SegmentDescriptor> segment=entry.getKey();
      Cache.NamedKey segmentCacheKey=entry.getValue();
      final Interval segmentQueryInterval=segment.rhs.getInterval();
      final byte[] cachedValue=cachedValues.get(segmentCacheKey);
      if (cachedValue != null) {
        segments.remove(segment);
        cachedResults.add(Pair.of(segmentQueryInterval,cachedValue));
      }
 else       if (populateCache) {
        final String segmentIdentifier=segment.lhs.getSegment().getIdentifier();
        cachePopulatorMap.put(String.format("%s_%s",segmentIdentifier,segmentQueryInterval),new CachePopulator(cache,objectMapper,segmentCacheKey));
      }
    }
  }
  for (  Pair<ServerSelector,SegmentDescriptor> segment : segments) {
    final QueryableDruidServer queryableDruidServer=segment.lhs.pick();
    if (queryableDruidServer == null) {
      log.makeAlert("No servers found for %s?! How can this be?!",segment.rhs).emit();
    }
 else {
      final DruidServer server=queryableDruidServer.getServer();
      List<SegmentDescriptor> descriptors=serverSegments.get(server);
      if (descriptors == null) {
        descriptors=Lists.newArrayList();
        serverSegments.put(server,descriptors);
      }
      descriptors.add(segment.rhs);
    }
  }
  return new LazySequence<>(new Supplier<Sequence<T>>(){
    @Override public Sequence<T> get(){
      ArrayList<Pair<Interval,Sequence<T>>> sequencesByInterval=Lists.newArrayList();
      addSequencesFromCache(sequencesByInterval);
      addSequencesFromServer(sequencesByInterval);
      return mergeCachedAndUncachedSequences(sequencesByInterval,toolChest);
    }
    private void addSequencesFromCache(    ArrayList<Pair<Interval,Sequence<T>>> listOfSequences){
      if (strategy == null) {
        return;
      }
      final Function<Object,T> pullFromCacheFunction=strategy.pullFromCache();
      final TypeReference<Object> cacheObjectClazz=strategy.getCacheObjectClazz();
      for (      Pair<Interval,byte[]> cachedResultPair : cachedResults) {
        final byte[] cachedResult=cachedResultPair.rhs;
        Sequence<Object> cachedSequence=new BaseSequence<>(new BaseSequence.IteratorMaker<Object,Iterator<Object>>(){
          @Override public Iterator<Object> make(){
            try {
              if (cachedResult.length == 0) {
                return Iterators.emptyIterator();
              }
              return objectMapper.readValues(objectMapper.getFactory().createParser(cachedResult),cacheObjectClazz);
            }
 catch (            IOException e) {
              throw Throwables.propagate(e);
            }
          }
          @Override public void cleanup(          Iterator<Object> iterFromMake){
          }
        }
);
        listOfSequences.add(Pair.of(cachedResultPair.lhs,Sequences.map(cachedSequence,pullFromCacheFunction)));
      }
    }
    private void addSequencesFromServer(    ArrayList<Pair<Interval,Sequence<T>>> listOfSequences){
      listOfSequences.ensureCapacity(listOfSequences.size() + serverSegments.size());
      final Query<Result<BySegmentResultValueClass<T>>> rewrittenQuery=(Query<Result<BySegmentResultValueClass<T>>>)query.withOverriddenContext(contextBuilder.build());
      final Queue<ListenableFuture<?>> cacheFutures=new ConcurrentLinkedQueue<>();
      for (      Map.Entry<DruidServer,List<SegmentDescriptor>> entry : serverSegments.entrySet()) {
        final DruidServer server=entry.getKey();
        final List<SegmentDescriptor> descriptors=entry.getValue();
        final QueryRunner clientQueryable=serverView.getQueryRunner(server);
        if (clientQueryable == null) {
          log.error("WTF!? server[%s] doesn't have a client Queryable?",server);
          continue;
        }
        final MultipleSpecificSegmentSpec segmentSpec=new MultipleSpecificSegmentSpec(descriptors);
        final List<Interval> intervals=segmentSpec.getIntervals();
        final Sequence<T> resultSeqToAdd;
        if (!server.isAssignable() || !populateCache || isBySegment) {
          if (!isBySegment) {
            resultSeqToAdd=clientQueryable.run(query.withQuerySegmentSpec(segmentSpec),responseContext);
          }
 else {
            @SuppressWarnings("unchecked") final Query<Result<BySegmentResultValueClass<T>>> bySegmentQuery=(Query<Result<BySegmentResultValueClass<T>>>)query;
            @SuppressWarnings("unchecked") final Sequence<Result<BySegmentResultValueClass<T>>> resultSequence=clientQueryable.run(bySegmentQuery.withQuerySegmentSpec(segmentSpec),responseContext);
            resultSeqToAdd=(Sequence)Sequences.map(resultSequence,new Function<Result<BySegmentResultValueClass<T>>,Result<BySegmentResultValueClass<T>>>(){
              @Override public Result<BySegmentResultValueClass<T>> apply(              Result<BySegmentResultValueClass<T>> input){
                final BySegmentResultValueClass<T> bySegmentValue=input.getValue();
                return new Result<>(input.getTimestamp(),new BySegmentResultValueClass<T>(Lists.transform(bySegmentValue.getResults(),toolChest.makePreComputeManipulatorFn(query,MetricManipulatorFns.deserializing())),bySegmentValue.getSegmentId(),bySegmentValue.getInterval()));
              }
            }
);
          }
        }
 else {
          @SuppressWarnings("unchecked") final Sequence<Result<BySegmentResultValueClass<T>>> runningSequence=clientQueryable.run(rewrittenQuery.withQuerySegmentSpec(segmentSpec),responseContext);
          resultSeqToAdd=toolChest.mergeSequencesUnordered(Sequences.<Result<BySegmentResultValueClass<T>>,Sequence<T>>map(runningSequence,new Function<Result<BySegmentResultValueClass<T>>,Sequence<T>>(){
            private final Function<T,Object> cacheFn=strategy.prepareForCache();
            @Override public Sequence<T> apply(            Result<BySegmentResultValueClass<T>> input){
              final BySegmentResultValueClass<T> value=input.getValue();
              final CachePopulator cachePopulator=cachePopulatorMap.get(String.format("%s_%s",value.getSegmentId(),value.getInterval()));
              final Collection<Object> cacheData=new ConcurrentLinkedQueue<>();
              return Sequences.<T>withEffect(Sequences.<T,T>map(Sequences.<T,T>map(Sequences.<T>simple(value.getResults()),new Function<T,T>(){
                @Override public T apply(                final T input){
                  if (cachePopulator != null) {
                    cacheFutures.add(backgroundExecutorService.submit(new Runnable(){
                      @Override public void run(){
                        cacheData.add(cacheFn.apply(input));
                      }
                    }
));
                  }
                  return input;
                }
              }
),toolChest.makePreComputeManipulatorFn((Query)rewrittenQuery,MetricManipulatorFns.deserializing())),new Runnable(){
                @Override public void run(){
                  if (cachePopulator != null) {
                    try {
                      Futures.allAsList(cacheFutures).get();
                      cachePopulator.populate(cacheData);
                      cacheFutures.clear();
                      cacheData.clear();
                    }
 catch (                    Exception e) {
                      log.error(e,"Error populating cache");
                      throw Throwables.propagate(e);
                    }
                  }
                }
              }
,backgroundExecutorService);
            }
          }
));
        }
        listOfSequences.add(Pair.of(new Interval(intervals.get(0).getStart(),intervals.get(intervals.size() - 1).getEnd()),resultSeqToAdd));
      }
    }
  }
);
}
