{
  testingCluster=new TestingCluster(1);
  testingCluster.start();
  cf=CuratorFrameworkFactory.builder().connectString(testingCluster.getConnectString()).retryPolicy(new ExponentialBackoffRetry(1,10)).compressionProvider(new PotentiallyGzippedCompressionProvider(true)).build();
  cf.start();
  cf.create().creatingParentsIfNeeded().forPath(testBasePath);
  jsonMapper=new DefaultObjectMapper();
  announcer=new Announcer(cf,MoreExecutors.sameThreadExecutor());
  announcer.start();
  segmentAnnouncer=new BatchDataSegmentAnnouncer(new DruidServerMetadata("id","host",Long.MAX_VALUE,"type","tier"),new ZkDataSegmentAnnouncerConfig(){
    @Override public String getZkBasePath(){
      return testBasePath;
    }
    @Override public int getSegmentsPerNode(){
      return 50;
    }
    @Override public long getMaxNumBytes(){
      return 100000;
    }
    @Override public String getAnnouncerType(){
      return "batch";
    }
  }
,announcer,jsonMapper);
  segmentAnnouncer.start();
  testSegments=Sets.newHashSet();
  for (int i=0; i < 100; i++) {
    testSegments.add(makeSegment(i));
  }
  batchServerInventoryView=new BatchServerInventoryView(new ServerInventoryViewConfig(){
    @Override public int getRemovedSegmentLifetime(){
      return 0;
    }
    @Override public String getAnnouncerType(){
      return "batch";
    }
  }
,new ZkPathsConfig(){
    @Override public String getZkBasePath(){
      return testBasePath;
    }
  }
,cf,Executors.newSingleThreadExecutor(),jsonMapper);
  batchServerInventoryView.start();
}
