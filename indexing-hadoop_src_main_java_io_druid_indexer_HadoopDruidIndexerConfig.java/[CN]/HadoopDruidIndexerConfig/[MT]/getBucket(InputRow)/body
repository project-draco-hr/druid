{
  final Optional<Interval> timeBucket=schema.getDataSchema().getGranularitySpec().bucketInterval(new DateTime(inputRow.getTimestampFromEpoch()));
  if (!timeBucket.isPresent()) {
    return Optional.absent();
  }
  final List<HadoopyShardSpec> shards=schema.getTuningConfig().getShardSpecs().get(timeBucket.get().getStart());
  if (shards == null || shards.isEmpty()) {
    return Optional.absent();
  }
  for (  final HadoopyShardSpec hadoopyShardSpec : shards) {
    final ShardSpec actualSpec=hadoopyShardSpec.getActualSpec();
    if (actualSpec.isInChunk(inputRow)) {
      return Optional.of(new Bucket(hadoopyShardSpec.getShardNum(),timeBucket.get().getStart(),actualSpec.getPartitionNum()));
    }
  }
  throw new ISE("row[%s] doesn't fit in any shard[%s]",inputRow,shards);
}
