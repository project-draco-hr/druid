{
  return new CacheStrategy<Row,Object,GroupByQuery>(){
    private static final byte CACHE_STRATEGY_VERSION=0x1;
    private final List<AggregatorFactory> aggs=query.getAggregatorSpecs();
    private final List<DimensionSpec> dims=query.getDimensions();
    @Override public byte[] computeCacheKey(    GroupByQuery query){
      final DimFilter dimFilter=query.getDimFilter();
      final byte[] filterBytes=dimFilter == null ? new byte[]{} : dimFilter.getCacheKey();
      final byte[] aggregatorBytes=QueryCacheHelper.computeAggregatorBytes(query.getAggregatorSpecs());
      final byte[] granularityBytes=query.getGranularity().cacheKey();
      final byte[][] dimensionsBytes=new byte[query.getDimensions().size()][];
      int dimensionsBytesSize=0;
      int index=0;
      for (      DimensionSpec dimension : query.getDimensions()) {
        dimensionsBytes[index]=dimension.getCacheKey();
        dimensionsBytesSize+=dimensionsBytes[index].length;
        ++index;
      }
      final byte[] havingBytes=query.getHavingSpec() == null ? new byte[]{} : query.getHavingSpec().getCacheKey();
      final byte[] limitBytes=query.getLimitSpec().getCacheKey();
      ByteBuffer buffer=ByteBuffer.allocate(2 + granularityBytes.length + filterBytes.length+ aggregatorBytes.length+ dimensionsBytesSize+ havingBytes.length+ limitBytes.length).put(GROUPBY_QUERY).put(CACHE_STRATEGY_VERSION).put(granularityBytes).put(filterBytes).put(aggregatorBytes);
      for (      byte[] dimensionsByte : dimensionsBytes) {
        buffer.put(dimensionsByte);
      }
      return buffer.put(havingBytes).put(limitBytes).array();
    }
    @Override public TypeReference<Object> getCacheObjectClazz(){
      return OBJECT_TYPE_REFERENCE;
    }
    @Override public Function<Row,Object> prepareForCache(){
      return new Function<Row,Object>(){
        @Override public Object apply(        Row input){
          if (input instanceof MapBasedRow) {
            final MapBasedRow row=(MapBasedRow)input;
            final List<Object> retVal=Lists.newArrayListWithCapacity(1 + dims.size() + aggs.size());
            retVal.add(row.getTimestamp().getMillis());
            Map<String,Object> event=row.getEvent();
            for (            DimensionSpec dim : dims) {
              retVal.add(event.get(dim.getOutputName()));
            }
            for (            AggregatorFactory agg : aggs) {
              retVal.add(event.get(agg.getName()));
            }
            return retVal;
          }
          throw new ISE("Don't know how to cache input rows of type[%s]",input.getClass());
        }
      }
;
    }
    @Override public Function<Object,Row> pullFromCache(){
      return new Function<Object,Row>(){
        private final QueryGranularity granularity=query.getGranularity();
        @Override public Row apply(        Object input){
          Iterator<Object> results=((List<Object>)input).iterator();
          DateTime timestamp=granularity.toDateTime(((Number)results.next()).longValue());
          Map<String,Object> event=Maps.newLinkedHashMap();
          Iterator<DimensionSpec> dimsIter=dims.iterator();
          while (dimsIter.hasNext() && results.hasNext()) {
            final DimensionSpec factory=dimsIter.next();
            event.put(factory.getOutputName(),results.next());
          }
          Iterator<AggregatorFactory> aggsIter=aggs.iterator();
          while (aggsIter.hasNext() && results.hasNext()) {
            final AggregatorFactory factory=aggsIter.next();
            event.put(factory.getName(),factory.deserialize(results.next()));
          }
          if (dimsIter.hasNext() || aggsIter.hasNext() || results.hasNext()) {
            throw new ISE("Found left over objects while reading from cache!! dimsIter[%s] aggsIter[%s] results[%s]",dimsIter.hasNext(),aggsIter.hasNext(),results.hasNext());
          }
          return new MapBasedRow(timestamp,event);
        }
      }
;
    }
    @Override public Sequence<Row> mergeSequences(    Sequence<Sequence<Row>> seqOfSequences){
      return new MergeSequence<>(getOrdering(),seqOfSequences);
    }
  }
;
}
