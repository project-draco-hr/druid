{
  Map<String,Set<DataSegment>> availableSegments=Maps.newHashMap();
  for (  DataSegment dataSegment : getAvailableDataSegments()) {
    Set<DataSegment> segments=availableSegments.get(dataSegment.getDataSource());
    if (segments == null) {
      segments=Sets.newHashSet();
      availableSegments.put(dataSegment.getDataSource(),segments);
    }
    segments.add(dataSegment);
  }
  Map<String,Set<DataSegment>> segmentsInCluster=Maps.newHashMap();
  for (  DruidServer druidServer : serverInventoryView.getInventory()) {
    for (    DruidDataSource druidDataSource : druidServer.getDataSources()) {
      Set<DataSegment> segments=segmentsInCluster.get(druidDataSource.getName());
      if (segments == null) {
        segments=Sets.newHashSet();
        segmentsInCluster.put(druidDataSource.getName(),segments);
      }
      segments.addAll(druidDataSource.getSegments());
    }
  }
  Map<String,Double> loadStatus=Maps.newHashMap();
  for (  Map.Entry<String,Set<DataSegment>> entry : availableSegments.entrySet()) {
    String dataSource=entry.getKey();
    Set<DataSegment> segmentsAvailable=entry.getValue();
    Set<DataSegment> loadedSegments=segmentsInCluster.get(dataSource);
    if (loadedSegments == null) {
      loadedSegments=Sets.newHashSet();
    }
    Set<DataSegment> unloadedSegments=Sets.difference(segmentsAvailable,loadedSegments);
    loadStatus.put(dataSource,100 * ((double)(segmentsAvailable.size() - unloadedSegments.size()) / (double)segmentsAvailable.size()));
  }
  return loadStatus;
}
